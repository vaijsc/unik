import json
from collections import defaultdict
from tqdm import tqdm
import os
from pathlib import Path

from utils.load_data import load_summ_data
from utils.eval import calc_rouge
from src.prompt_template import PROMPT_SUMMARIZATION

class LLMSum():
    def __init__(self, llm, is_opensource=False) -> None:
        self.llm = llm
        self.is_opensource = is_opensource

    def load_graph(self, file_path, aspect=None):
        with open(file_path, 'r', encoding='utf-8') as f:
            lines = f.readlines()

        entity_data = defaultdict(lambda: defaultdict(lambda: {'expressions': set(), 'descriptions': set()}))
        aspect_flag = []
        for line in lines:
            data = json.loads(line.strip())
            entity_id = data['entity_id']

            if aspect != 'general': 
                if (data['aspect'] != aspect):
                    continue
            else:
                if (data['aspect'] == aspect):
                    continue
            
            if data['aspect'] not in aspect_flag:
                for item in data['data']:
                    feature = item['feature']
                    expression = item['expression']
                    descriptions = item['descriptions']
                    entity_data[entity_id][feature]['expressions'].add(expression)
                    entity_data[entity_id][feature]['descriptions'].update(descriptions)

                    if data['aspect'] == 'general':
                        aspect_flag.append(data['aspect'])

        for entity_id in entity_data:
            for feature in entity_data[entity_id]:
                entity_data[entity_id][feature]['expressions'] = list(entity_data[entity_id][feature]['expressions'])
                entity_data[entity_id][feature]['descriptions'] = sorted(entity_data[entity_id][feature]['descriptions'], key=len)

        return entity_data

    def load_structured_data(self, entity_data):
        kg = defaultdict(list)
        tsk = defaultdict(list)
        for entity_id, features in entity_data.items():
            for feature, data in features.items():
                if data['expressions'] and data['descriptions']:
                    shortest_description = data['descriptions'][0]
                    expression = " ".join(data['expressions'])
                    text = f"{feature}, {expression}."
                    kg[entity_id].append(text)
                    tsk[entity_id].append(shortest_description)
        return kg, tsk
    
    def process(self, sub_graphs, data, eval_output, summaries, llm_active = False):
        # data config
        dataset_name = data.name
        aspect_names = data.aspects
        
        # output  -> saved -> summaries_storage
        summaries_storage = Path(summaries)
        os.makedirs(summaries_storage.parent, exist_ok=True)
        writer = open(summaries_storage, "w")

        # generate summarization  
        for aspect_name in aspect_names:
            # load golden summaries labels
            _, test_data = load_summ_data(
                data.raw.summ_data_path,
                data.raw.summ_splits_path,
                aspect_name=aspect_name,
            )
            references = []
            for idx, entity in tqdm(enumerate(test_data), desc= aspect_name + "-Eval Examples", ncols=100):
                references.append(entity["labels"])

            # load summaries generated by LLMs
            entity_data = self.load_graph(sub_graphs, aspect_name)
            kg, tsk = self.load_structured_data(entity_data)
            
            responses = []
            for idx in tqdm(kg.keys(), desc="gen sum: "):
                kg_info = " ".join(kg[idx])
                tsk_info = " ".join(tsk[idx])
                if llm_active:
                    response = self.llm.process(PROMPT_SUMMARIZATION.format(kg_info=kg_info, tsk_info=tsk_info))
                else:
                    response = kg_info
                responses.append(response)
                output = {
                    "idx": idx,
                    "aspect": aspect_name,
                    "summary": response,
                }  
                #save to output file
                json.dump(output, writer)
                writer.write("\n")
        
            # Evaluation
            result = calc_rouge(responses, references)
            print("Result-" + aspect_name + ": " )
            print(result)
            with open(eval_output, "w") as f:
                f.write(aspect_name + ": ")
                json.dump(result, f)
                f.write("\n")
        writer.close()

if __name__ == '__main__':
    pass